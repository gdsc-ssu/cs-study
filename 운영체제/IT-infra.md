# 1주차 [~2장]

클라우드가 대세가 됐으며, 도커 등의 컨테이너가 주류로 자리 잡으면서 인프라에도 나름 변화가 생겼습니다.

하지만 인프라 기술의 핵심은 변하지 않았습니다.

IT 인프라 기술은 클라우드화를 향해 진화하고 있으며, 시스템의 일부가 클라우드 상에서 실행되고 있을 겁니다.

### 클라우드 시대에 IT 인프라 지식이 필요할까??

클라우드 자체는 미들웨어 기술이나 자동화 기술의 연장선상에 있는 것으로, 내부에서 움직이고 있는 IT 인프라가 근본적으로 바뀌는 것은 아닙니다. 더 효율적이고 구축 및 운용 비용이 적게 드는 시스템을 만들 수 있게 될 것입니다.

---

# 1장 인프라 아키텍처

인프라 = 기반

아키텍처 = 구조

<aside>
💡 집약과 분할
수직 분할
수평 분할
지리분할
+추상화

</aside>

## 집약형과 분할형  아키텍처

### **집약형**

하나의 컴퓨터로 모든 처리를 합니다

장점

- 한 대의 대형 컴퓨터만 있으면 되므로 구성이 간단합니다.  (하나의 컴퓨터지만 그 안에 여러 사람이 동거하고 있다)
- 대형 컴퓨터의 리소스 관리나 이중화에 의해 안정성이 높고 고성능입니다.

단점

- 대형 컴퓨터의 도입 비용과 유지 비용이 비싸다
- 확장성에 한계가 있다

### **분할형**

여래대의 컴퓨터를 조합해서 하나의 시스템 구축

장점

- 낮은 비용으로 시스템을 구축할 수 있다
- 서버 대수를 늘릴 수 있어서 확작성이 높다

단점

- 대수가 늘어나면 관리 구조가 복잡해진다
- 한 대가 망가지면 영향 범위를 최소화 하기 위한 구조를 검토해야 한다

컴퓨터 자체를 가리키는 경우 ‘물리 서버’, 컴퓨터 내부에서는 여러 소프트웨어(논리적인)서버가 동작

## 수직 분할형 아키텍처

분할형에서는 각각의 서버가 전혀 다른 작업을 하는지, 아니면 비슷한 작업을 하는 것 인지에 대한 관점

수직 분할형 아키텍처 : 서버별로 다른 역할을 담당

### 클라이언트-서버

클라이언트-서버형의 특징은 클라이언트 측에 전용 소프트웨어를 설치해야 한다는 것

장점

- 클라이언트 측에서 많은 처리를 실행할 수 있어서 소수의 서버로 다수의 클라이언트를 처리할 수 있다

단점

- 클라이언트 측의 소프트웨어 정기 업데이트가 필요하다
- 서버 확장성에 한계가 발생할 수 있다

→ 단점 개선을 위해 3계층형 등장

### 3계층형 아키텍처

1. 프레젠테이션 계층
    1. 사용자 입력을 받는다
    2. 웹 브라우저 화면을 표시한다
2. 애플리케이션 계층
    1. 사용자 요청에 따라 업무 처리를 한다
3. 데이터 계층
    1. 애플리케이션 계층의 요청에 따라 데이터 입출력을 한다

특정 서버에 부하가 집중되는 문제가 해결된다는 것이 장점입니다.

또한 업무 애플리케이션 갱신에 따른 클라이언트 업데이트가 필요 없으며, 사용자는 웹 브라우저만 준비하면 됩니다.

장점

- 서버 부하 집중 개선
- 클라이언트 단말의 정기 업데이트가 불필요
- ‘처리 반환’에 의한 서버 부하 저감

단점

- 구조가 클라이언트-서버 구성보다 복잡하다

## 수평 분할형 아키텍처

더 높은 확작성을 실현하기 위해 다른 하나의 축으로 분할하는 것이 필요합니다.

수평 분할형 아키텍처는 용도가 같은 서버를 늘려나가는 방식입니다.

서버 대수가 늘어나면 한 대가 시스템에 주는 영향력이 낮아져서 안정성이 향상되고 처리를 담당하는 서버 대수가 늘어나면 전체적인 성능 향상도 실현할 수 있습니다.

### 단순 수평 분할형 아키텍처

수평 분할을 sharding, partitioning 라고도 불립니다.

이 구성에서는 시스템이 둘로 분할됨으로써 시스템 전체 처리 성능을 두 배로 향상시킬 수 있습니다.

두 개의 독립된 시스템이 생성되기에 각 시스템에는 서로 영향을 주지 않기 때문에 독립성이 향상됩니다.

단 만약 A 시스템에 이용자 수가 많다면 시스템 과부하가 걸리고 이런 상태에서는 시스템 처리 성능이 두 배가 되었다고 하기 어렵겠죠??

장점

- 수평으로 서버를 늘리기 때문에 확장성이 향상된다
- 분할한 시스템이 독립적으로 운영되므로 서로 영향을 주지 않는다

단점

- 데이터를 일원화해서 볼 수 없다
- 애플리케이션 업데이트는 양쪽을 동시에 해 주어야 한다
- 처리량이 균등하게 분할돼 있지 않으면 서버별 처리량에 치우침이 생긴다

### 공유형 아키텍처

단순 분할형과 달리 일부 계층에서 상호 접속이 이루어집니다

장점

- 수평으로 서버를 늘리기 때문에 확장성이 향상된다
- 분할한 시스템이 서로 다른 시스템의 데이터를 참조할 수 있다

단점

- 분할한 시스템 간 독립성이 낮아진다
- 공유한 계층의 확장성이 낮아진다

## 지리 분할형 아키텍처

업무 연속성 및 시스템 가용성을 높이기 위한 방식으로 지리적으로 분할하는 아키텍처에 대해서 알아보겠습니다.

### 스탠바이형 아키텍처 (HA 구성, 액티브-스탠바이구성)

물리 서버를 최소 두 대를 준비하여 한 대가 고장 나면 가동 중인 소프트웨어를 다른 한 대로 옮겨서 운영하는 방식입니다. 

이 때 소프트웨어  재시작을 자동으로 하는 구조를 ‘failover’라고 합니다. (F/O 라고도 부르죠)

하지만 항상 대기중인 상태로 있으면 리소스 측면에서 낭비가 심하기 때문에 이를 해결하기 위해 스탠바이를 따로 두지 않고, 양쪽 서버를 동시에 교차 이용하는 경우도 많습니다.

### 재해 대책형 아키텍처

특정 데이터 센터에 있는 상용 환경에 고장이 발생하면 다른 사이트에 있는 재해 대책 환경에서 업무 처리를 재개하는 것을 가리킵니다.

---

# 서버를 열어 보자

## 물리 서버

### 서버 외관과 설치 장소

서버실을 본 적이 있을까요?? 

![Untitled](1%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%5B~2%E1%84%8C%E1%85%A1%E1%86%BC%5D%20a9371720355041a0abf7e97f163f39dc/Untitled.png)

그림과 같이 서버가 대량으로 설치되어 있고 서버에서 나오는 열기를 식히기 위해 실내 온도를 항상 낮게설정합니다.

서버는 랙이라는 장비에 장착이 되는데 서버 외에도 HDD가 장착되어 있는 저장소나 네트워크 스위치 등도 탑재되어 있습니다.

서버 설치 시 중요한 정보는 다음과 같습니다.

1. 서버 크기
2. 소비 전력
3. 중량

CPU와 메모리는 물리적으로 직접 연결되어 있습니다.

PCI Express 슬롯은 외부 장치를 연결하는 곳으로 Xeon  확장 프로세서 아키텍처에선 CPU가 PCI를 직접 제어합니다.

BMC라는 컴포넌트는 서버 H/W 상태를 감시하며 , 독립적으로 움직입니다.

(컴포넌트란 여러 개의 프로그램 함수들을 모아 하나의 특정한 기능을 수행할 수 있도록 구성한 작은 단위를 말합니다.)

서버와 PC는 물리적으로 기본 구성이 같습니다. 다른점은 전원이 이중화되어 있어 장애에 강하고 대용량 CPU나 메모리가 탑재되어 있는 정도입니다. 

## CPU (Central Processing Unit)

서버 중심에 위치해서 연산 처리를 실시합니다.

CPU는 명령을 받아서 연산을 실행하고 결과를 반환합니다. 명령과 데이터는 기억 장치나 입출력 장치를 통해 전달됩니다.  

현재는 CPU를 코어라고 부르며, 하나의 CPU에 여러개의 코어가 존재하는 멀티 코어화가 진행되고 있으며, 코어는 각자가 독립된 처리를 할 수 있습니다.

명령과 데이터는 기억 장치에 있다는 걸 알겠는데 과연 누가 명령을 내리는 걸까요??

OS라는 소프트웨어가 명령을 내립니다. 

그럼 OS에게는 누가 명령을 내릴까요??

OS에서 동작하는 웹 서버나 데이터베이스의 실체인  ‘프로세스’ 와 사용자 키보드, 마우스 등을 통한 입력입니다.

## 메모리

메모리는 기억 영역을 말합니다. CPU 옆에 위치하며 CPU에 전달하는 내용이나 데이터를 저장하거나 처리 결과를 받습니다.                                                                                                                

메모리에 저장되는 정보는 영구성이 없어 서버를 재시작하면 정보가 날라갑니다. 

이럼 결점에도 메모리를 사용하는 이유는 메모리 엑세스가 매우 빠르게 이루어지고 데이터 저장 시에 물리적인 모터를 구동하는 것이 아닌 전기적인 처리만으로 데이터를 저장하기 때문입니다.

캐시 메모리

시간적, 공간적 지역성을 기반으로 가까운 미래에 접근될 확률이 높은 데이터를 작지만 빠른 캐시 메모리에 미리 보관하여 전체적인 시스템의 성능을 높인다.

캐시 메모리 저장 규칙

1. 최근에 접근된 데이터
- Temporal Locality - 시간적 지역성
1. 최근에 접근된 데이터의 주변 데이터
- Spatial Locality - 공간적 지역성

## I/O 장치

### HDD

서버에서는 메모리에 비해 CPU에서 떨어진 곳에 HDD가 배치됩니다. 

주로 장기 저장 목적의 데이터 저장 장소로 사용됩니다. 

최근에는 기술이 발달해서 SSD (Solid State Disk 반도체 디스크)라는 물리적인 회전 요소를 사용하지 않는 디스크가 사용되고 있습니다. 전기가 없어도 데이터가 사라지지 않는 특성이 있습니다.

<aside>
💡 ▶Write Through란?

CPU가 데이터를 사용하면 캐시에 저장되게 되는데, 데이터가 캐시 됨과 동시에 주기억장치 또는 디스크로 기입되는 방식을 지원하는 구조의 캐시이다. 즉, 캐시와 메모리 둘다에 업데이트를 해버리는 방식이다.장점 : 캐시와 메모리에 업데이트를 같이 하여, 데이터 일관성을 유지할 수 있어서 안정적이다.단점 : 속도가 느린 주기억장치 또는 보조기억장치에 데이터를 기록할 때, CPU가 대기하는 시간이 필요하기 때문에 성능이 떨어진다.

데이터 로스가 발생하면 안되는 상황에서는 Write Through를 사용하는 것이 좋다.

▶Write Back이란?

CPU 데이터를 사용할 때 데이터는 먼저 캐시로 기록되는데, 캐시 내에 일시적으로 저장된 후에 블록 단위에 캐시로부터 해제되는 때(캐시안에 있는 내용을 버릴시) 에만 주기억장치 또는 보조기억장치에 기록되는 방식이다. 즉, 데이터를 쓸 때 메모리에는 쓰지 않고 캐시에만 업데이트를 하다가 필요할 때에만 주기억장치나 보조기억장치에 기록하는 방법이다.장점 : Write Through보다 훨씬 빠르다.단점 : 속도가 빠르지만 캐시에 업데이트 하고 메모리에는 바로 업데이트를 하지 않기 때문에, 캐시와 메모리가 서로 값이 다른 경우가 발생할 때가 있다.

빠른 서비스를 요하는 상황에서는 Write Back을 사용하는 것이 좋다.

</aside>

### 네트워크 인터페이스

서버와 외부 장비를 연결하기 위한 것으로 외부 접속용 인터페이스입니다.

### I/O 제어

IO 제어는 발전 속도가 빨라서 일반적인 구성이라는게 없습니다. 

## 버스

버스는 서버 내부에 있는 컴포넌트들을 서로 연결시키는 회선을 가리킵니다.

버스에서 중요한 것은 버스가 어느정도의 데이터 전송 능력을 가지고 있는지?, 즉, 대역이 어느 정도인지가 중요합니다.

### 대역

대역은 데이터 전송 능력을 의미합니다.

대역은 *한번에 데이터를 보낼 수 있는 데이터 폭* x *1초에 전송할 수 있는 횟수* 로 결정됩니다.

### 버스 대역

CPU에 가까운 쪽이 1초당 전송량이 크다는 것을 확인할 수 있습니다.

버스 흐름에서 중요한 것은 CPU와 장치 사이에 병목 현상이 없어야 한다는 것입니다.